{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EliasAI_task2_A.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4D-d7EqXIPN"
      },
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dropout, Flatten,Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gclF_U9odTI7"
      },
      "source": [
        "import os\n",
        "import zipfile\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJLCA4YWepxv"
      },
      "source": [
        "# drive.mount('/content/drive/')\n",
        " \n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/flowers_dataset.zip\", 'r')\n",
        "zip_ref.extractall(\"/tmp/flowers_dataset\")\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvhNO7PQnJTx"
      },
      "source": [
        "\n",
        "X=[]\n",
        "Z=[]\n",
        "IMG_SIZE=200\n",
        "daisy_dir='/tmp/flowers_dataset/flowers/daisy'\n",
        "sunflower_dir='/tmp/flowers_dataset/flowers/sunflower'\n",
        "tulip_dir='/tmp/flowers_dataset/flowers/tulip'\n",
        "dandelion_dir='/tmp/flowers_dataset/flowers/dandelion'\n",
        "rose_dir='/tmp/flowers_dataset/flowers/rose'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bTd-KdTnD5Z"
      },
      "source": [
        "def assign_label(img,flower_type):\n",
        "    return flower_type\n",
        "    \n",
        "def make_train_data(flower_type,DIR):\n",
        "      for img in tqdm(os.listdir(DIR)):\n",
        "        _, ftype = os.path.splitext(img)\n",
        "        if ftype == \".jpg\": \n",
        "          label=assign_label(img,flower_type)\n",
        "          path = os.path.join(DIR,img)\n",
        "          img = cv2.imread(path)\n",
        "          img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
        "          \n",
        "          X.append(np.array(img))\n",
        "          Z.append(str(label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDiRpbq8dTLb",
        "outputId": "1e6abd1b-b40e-47ee-d15c-b89d2aa6773f"
      },
      "source": [
        "make_train_data('Daisy',daisy_dir)\n",
        "make_train_data('Sunflower',sunflower_dir)\n",
        "make_train_data('Tulip',tulip_dir)\n",
        "make_train_data('Rose',rose_dir)\n",
        "make_train_data('Dandelion',dandelion_dir)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 769/769 [00:02<00:00, 371.62it/s]\n",
            "100%|██████████| 734/734 [00:02<00:00, 309.10it/s]\n",
            "100%|██████████| 984/984 [00:02<00:00, 347.07it/s]\n",
            "100%|██████████| 784/784 [00:02<00:00, 374.91it/s]\n",
            "100%|██████████| 1055/1055 [00:03<00:00, 344.35it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXcx8HZsd3JN"
      },
      "source": [
        "le=LabelEncoder()\n",
        "Y=le.fit_transform(Z)\n",
        "Y=to_categorical(Y,5)\n",
        "X=np.array(X)\n",
        "X=X/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDuSyHxZd3Ln"
      },
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.19,random_state=42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ybydExtd3OF",
        "outputId": "4addedc9-c12f-4501-bb80-750719296cc7"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "         rescale=1/255)  \n",
        "\n",
        "# datagen.fit(x_train)\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "        '/tmp/flowers_dataset/flowers/',  # This is the source directory for training images\n",
        "        target_size=(200, 200),  # All images will be resized to 150x150\n",
        "        batch_size=128,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4323 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e86wRPXjMKq7"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 200x200 with 3 bytes color\n",
        "    # This is the first convolution\n",
        "    tf.keras.layers.Conv2D(32, (5,5), activation='relu', padding='same', input_shape=(200, 200, 3)),\n",
        "    # tf.keras.layers.Conv2D(96, (5,5), activation='relu', padding='same'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(96, (3,3), activation='relu', padding='same'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fourth convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # # The fifth convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
        "    # tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(288, activation='relu'),\n",
        "    # tf.keras.layers.Dropout(0.4),\n",
        "    # tf.keras.layers.Dense(512, activation='relu'),\n",
        "    # tf.keras.layers.Dropout(0.4),\n",
        "    # tf.keras.layers.Dense(128, activation='relu'),\n",
        "    # tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjHqyfX-8B1g",
        "outputId": "46ac1080-98ed-4dd0-a389-8b5a0dbb000a"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 200, 200, 32)      2432      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 100, 100, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 100, 100, 96)      27744     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 50, 50, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 50, 50, 64)        55360     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 25, 25, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 25, 25, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 10, 10, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 3, 3, 16)          9232      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 144)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 288)               41760     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 1445      \n",
            "=================================================================\n",
            "Total params: 211,829\n",
            "Trainable params: 211,829\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TE4dYi34lsY"
      },
      "source": [
        "model.compile(optimizer=RMSprop(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wac_5Lkl40yf",
        "outputId": "0dda9f78-5f99-4b9f-f69c-2bf719188028"
      },
      "source": [
        "batch_size=128\n",
        "epochs=60\n",
        "History = model.fit(train_generator,\n",
        "                              epochs = epochs, validation_data = (x_test,y_test),\n",
        "                              verbose = 1, steps_per_epoch=8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "8/8 [==============================] - 127s 16s/step - loss: 1.6702 - accuracy: 0.2119 - val_loss: 1.6064 - val_accuracy: 0.2263\n",
            "Epoch 2/60\n",
            "8/8 [==============================] - 124s 16s/step - loss: 1.6047 - accuracy: 0.2185 - val_loss: 1.6839 - val_accuracy: 0.1946\n",
            "Epoch 3/60\n",
            "8/8 [==============================] - 123s 16s/step - loss: 1.7362 - accuracy: 0.2130 - val_loss: 1.7907 - val_accuracy: 0.2311\n",
            "Epoch 4/60\n",
            "8/8 [==============================] - 123s 16s/step - loss: 1.5630 - accuracy: 0.3124 - val_loss: 1.5982 - val_accuracy: 0.2299\n",
            "Epoch 5/60\n",
            "8/8 [==============================] - 124s 16s/step - loss: 1.5135 - accuracy: 0.2931 - val_loss: 1.5492 - val_accuracy: 0.3029\n",
            "Epoch 6/60\n",
            "8/8 [==============================] - 125s 16s/step - loss: 1.6585 - accuracy: 0.3096 - val_loss: 1.5904 - val_accuracy: 0.2238\n",
            "Epoch 7/60\n",
            "8/8 [==============================] - 124s 16s/step - loss: 1.4689 - accuracy: 0.3519 - val_loss: 1.6448 - val_accuracy: 0.3114\n",
            "Epoch 8/60\n",
            "8/8 [==============================] - 124s 16s/step - loss: 1.3651 - accuracy: 0.4420 - val_loss: 1.9418 - val_accuracy: 0.2384\n",
            "Epoch 9/60\n",
            "8/8 [==============================] - 125s 16s/step - loss: 1.2713 - accuracy: 0.4642 - val_loss: 1.7126 - val_accuracy: 0.2336\n",
            "Epoch 10/60\n",
            "8/8 [==============================] - 123s 16s/step - loss: 1.2582 - accuracy: 0.4547 - val_loss: 1.6399 - val_accuracy: 0.2640\n",
            "Epoch 11/60\n",
            "8/8 [==============================] - 123s 16s/step - loss: 1.2146 - accuracy: 0.4977 - val_loss: 1.7700 - val_accuracy: 0.2555\n",
            "Epoch 12/60\n",
            "8/8 [==============================] - 123s 16s/step - loss: 1.0884 - accuracy: 0.5645 - val_loss: 1.5945 - val_accuracy: 0.2993\n",
            "Epoch 13/60\n",
            "8/8 [==============================] - 124s 16s/step - loss: 1.1735 - accuracy: 0.5214 - val_loss: 1.6723 - val_accuracy: 0.3418\n",
            "Epoch 14/60\n",
            "8/8 [==============================] - 123s 16s/step - loss: 1.3920 - accuracy: 0.4185 - val_loss: 1.8376 - val_accuracy: 0.2762\n",
            "Epoch 15/60\n",
            "8/8 [==============================] - 125s 16s/step - loss: 1.1460 - accuracy: 0.5403 - val_loss: 1.6980 - val_accuracy: 0.2749\n",
            "Epoch 16/60\n",
            "8/8 [==============================] - 124s 16s/step - loss: 1.0564 - accuracy: 0.5486 - val_loss: 1.5886 - val_accuracy: 0.3382\n",
            "Epoch 17/60\n",
            "8/8 [==============================] - 124s 16s/step - loss: 1.1301 - accuracy: 0.5379 - val_loss: 1.6295 - val_accuracy: 0.2676\n",
            "Epoch 18/60\n",
            "8/8 [==============================] - 123s 16s/step - loss: 1.0399 - accuracy: 0.5849 - val_loss: 1.6423 - val_accuracy: 0.3212\n",
            "Epoch 19/60\n",
            "8/8 [==============================] - 124s 16s/step - loss: 1.0677 - accuracy: 0.6083 - val_loss: 1.6369 - val_accuracy: 0.3236\n",
            "Epoch 20/60\n",
            "8/8 [==============================] - 122s 15s/step - loss: 1.0537 - accuracy: 0.5756 - val_loss: 1.8426 - val_accuracy: 0.3078\n",
            "Epoch 21/60\n",
            "8/8 [==============================] - 124s 16s/step - loss: 0.9479 - accuracy: 0.6120 - val_loss: 1.5855 - val_accuracy: 0.3066\n",
            "Epoch 22/60\n",
            "8/8 [==============================] - 121s 16s/step - loss: 1.1026 - accuracy: 0.5750 - val_loss: 1.4965 - val_accuracy: 0.3589\n",
            "Epoch 23/60\n",
            "8/8 [==============================] - 123s 16s/step - loss: 1.0069 - accuracy: 0.6094 - val_loss: 1.4582 - val_accuracy: 0.3260\n",
            "Epoch 24/60\n",
            "8/8 [==============================] - 123s 16s/step - loss: 1.0164 - accuracy: 0.6085 - val_loss: 1.3613 - val_accuracy: 0.4319\n",
            "Epoch 25/60\n",
            "8/8 [==============================] - 121s 15s/step - loss: 1.0511 - accuracy: 0.5701 - val_loss: 1.5370 - val_accuracy: 0.3686\n",
            "Epoch 26/60\n",
            "8/8 [==============================] - 123s 16s/step - loss: 0.9410 - accuracy: 0.6270 - val_loss: 1.5231 - val_accuracy: 0.3467\n",
            "Epoch 27/60\n",
            "8/8 [==============================] - 123s 16s/step - loss: 0.9550 - accuracy: 0.6604 - val_loss: 1.7166 - val_accuracy: 0.3187\n",
            "Epoch 28/60\n",
            "8/8 [==============================] - 121s 15s/step - loss: 0.9163 - accuracy: 0.6675 - val_loss: 2.1817 - val_accuracy: 0.2774\n",
            "Epoch 29/60\n",
            "8/8 [==============================] - 124s 16s/step - loss: 0.9907 - accuracy: 0.6056 - val_loss: 1.4100 - val_accuracy: 0.3905\n",
            "Epoch 30/60\n",
            "8/8 [==============================] - 121s 15s/step - loss: 0.9567 - accuracy: 0.6318 - val_loss: 1.8376 - val_accuracy: 0.2762\n",
            "Epoch 31/60\n",
            "8/8 [==============================] - 123s 16s/step - loss: 1.0032 - accuracy: 0.5988 - val_loss: 1.4567 - val_accuracy: 0.3698\n",
            "Epoch 32/60\n",
            "8/8 [==============================] - 122s 16s/step - loss: 0.9897 - accuracy: 0.6187 - val_loss: 1.3844 - val_accuracy: 0.4343\n",
            "Epoch 33/60\n",
            "8/8 [==============================] - 125s 16s/step - loss: 0.9313 - accuracy: 0.6322 - val_loss: 1.4560 - val_accuracy: 0.3674\n",
            "Epoch 34/60\n",
            "8/8 [==============================] - 123s 16s/step - loss: 0.8758 - accuracy: 0.6533 - val_loss: 1.3922 - val_accuracy: 0.4270\n",
            "Epoch 35/60\n",
            "8/8 [==============================] - 124s 16s/step - loss: 0.8794 - accuracy: 0.6497 - val_loss: 1.4974 - val_accuracy: 0.3650\n",
            "Epoch 36/60\n",
            "8/8 [==============================] - 124s 16s/step - loss: 0.8848 - accuracy: 0.6605 - val_loss: 1.5469 - val_accuracy: 0.3735\n",
            "Epoch 37/60\n",
            "8/8 [==============================] - 124s 16s/step - loss: 0.8578 - accuracy: 0.6662 - val_loss: 1.4850 - val_accuracy: 0.3455\n",
            "Epoch 38/60\n",
            "8/8 [==============================] - 125s 16s/step - loss: 0.8216 - accuracy: 0.6902 - val_loss: 2.0700 - val_accuracy: 0.2895\n",
            "Epoch 39/60\n",
            "8/8 [==============================] - 123s 16s/step - loss: 0.8722 - accuracy: 0.6744 - val_loss: 1.6551 - val_accuracy: 0.3613\n",
            "Epoch 40/60\n",
            "8/8 [==============================] - 124s 16s/step - loss: 0.8216 - accuracy: 0.6624 - val_loss: 1.5631 - val_accuracy: 0.3686\n",
            "Epoch 41/60\n",
            "8/8 [==============================] - 124s 16s/step - loss: 0.8045 - accuracy: 0.6884 - val_loss: 1.4751 - val_accuracy: 0.3881\n",
            "Epoch 42/60\n",
            "8/8 [==============================] - 124s 16s/step - loss: 0.8636 - accuracy: 0.6603 - val_loss: 1.5083 - val_accuracy: 0.3686\n",
            "Epoch 43/60\n",
            "8/8 [==============================] - 124s 16s/step - loss: 0.8941 - accuracy: 0.6657 - val_loss: 1.5211 - val_accuracy: 0.3917\n",
            "Epoch 44/60\n",
            "8/8 [==============================] - 123s 16s/step - loss: 0.8615 - accuracy: 0.6694 - val_loss: 1.6502 - val_accuracy: 0.3808\n",
            "Epoch 45/60\n",
            "8/8 [==============================] - 125s 16s/step - loss: 0.8325 - accuracy: 0.7003 - val_loss: 1.4692 - val_accuracy: 0.3735\n",
            "Epoch 46/60\n",
            "8/8 [==============================] - 125s 16s/step - loss: 0.7986 - accuracy: 0.7141 - val_loss: 1.4330 - val_accuracy: 0.4343\n",
            "Epoch 47/60\n",
            "8/8 [==============================] - 125s 16s/step - loss: 0.7831 - accuracy: 0.6816 - val_loss: 1.5143 - val_accuracy: 0.3723\n",
            "Epoch 48/60\n",
            "8/8 [==============================] - 124s 16s/step - loss: 0.7863 - accuracy: 0.7062 - val_loss: 1.3233 - val_accuracy: 0.4781\n",
            "Epoch 49/60\n",
            "8/8 [==============================] - 125s 16s/step - loss: 0.7442 - accuracy: 0.7140 - val_loss: 1.3663 - val_accuracy: 0.4489\n",
            "Epoch 50/60\n",
            "8/8 [==============================] - 126s 16s/step - loss: 0.8766 - accuracy: 0.6650 - val_loss: 1.4955 - val_accuracy: 0.3869\n",
            "Epoch 51/60\n",
            "8/8 [==============================] - 123s 16s/step - loss: 0.7402 - accuracy: 0.7309 - val_loss: 1.4902 - val_accuracy: 0.4124\n",
            "Epoch 52/60\n",
            "8/8 [==============================] - 124s 16s/step - loss: 0.7154 - accuracy: 0.7339 - val_loss: 1.3847 - val_accuracy: 0.4294\n",
            "Epoch 53/60\n",
            "8/8 [==============================] - 122s 16s/step - loss: 0.7152 - accuracy: 0.7347 - val_loss: 1.3083 - val_accuracy: 0.4708\n",
            "Epoch 54/60\n",
            "8/8 [==============================] - 124s 16s/step - loss: 0.7259 - accuracy: 0.7356 - val_loss: 1.4238 - val_accuracy: 0.4209\n",
            "Epoch 55/60\n",
            "8/8 [==============================] - 121s 15s/step - loss: 0.8423 - accuracy: 0.6618 - val_loss: 1.5245 - val_accuracy: 0.3869\n",
            "Epoch 56/60\n",
            "8/8 [==============================] - 125s 16s/step - loss: 0.6507 - accuracy: 0.7508 - val_loss: 1.7483 - val_accuracy: 0.3443\n",
            "Epoch 57/60\n",
            "8/8 [==============================] - 126s 16s/step - loss: 0.7043 - accuracy: 0.7377 - val_loss: 1.4293 - val_accuracy: 0.4221\n",
            "Epoch 58/60\n",
            "8/8 [==============================] - 125s 16s/step - loss: 0.7535 - accuracy: 0.6976 - val_loss: 1.5812 - val_accuracy: 0.4270\n",
            "Epoch 59/60\n",
            "8/8 [==============================] - 125s 16s/step - loss: 0.7634 - accuracy: 0.7259 - val_loss: 1.4597 - val_accuracy: 0.3978\n",
            "Epoch 60/60\n",
            "8/8 [==============================] - 122s 16s/step - loss: 0.7113 - accuracy: 0.7275 - val_loss: 1.3492 - val_accuracy: 0.4112\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXVgz_eYXc2P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1--YufFXc5A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwMCMjE6Xc7h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fUSbOMRXc-Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSQqCfnZXdBS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a3vWzWHXdDt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xn9TzgfXXdGZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8lnQCZlXdIx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}